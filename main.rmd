---
title: "HDT7-SMV"
author: "Mariana David, Alejandra Guzman, Jorge Caballeros"
date: "21/4/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Analisis
En esta HDT se trabajara con el modelo svm de la librería e1071  y varias otras funciónes que requieren transformaciónes de data. Primero se nos pide que se genere una variable que defina entre economico, caro e intermedio que ya se había hecho en hojas de trabajo pasadas. Dado que los datos máximos atípicos afectan considerablemente a una predicción, no se categorizan entre ninguna de las tres clasificaciónes por lo que se producen valores NA en nuestra variable tipoDeCasa. Para solventar este problema, eliminaremos las filas que tienen NA en la variable tipoDeCasa. Tambien es importante que las variables cuantitativas no tengan NA en ellas, por lo que las cambiamos por 0 tomando en cuenta lo que representa cada variable.
```{r echo=FALSE, message=FALSE, warning=FALSE}
library(e1071)
library(caret)
library(corrplot)
library(labelled)
library(plotly)
library(ggplot2)
# Load Data
set.seed(123)
df = read.csv("./train.csv")
df[is.na(df)] <- 0
df$tipoDeCasa = as.numeric(as.character( cut(df$SalePrice,c(0,145000,205000,410000), labels = c(1, 2, 3))))
df[sapply(df, is.character)] <- lapply(df[sapply(df, is.character)],as.factor)
#Para borrar filas que tengan NA en una columna en especifico.
#https://stackoverflow.com/questions/11254524/omit-rows-containing-specific-column-of-na
completeFun <- function(data, desiredCols) {
  completeVec <- complete.cases(data[, desiredCols])
  return(data[completeVec, ])
}
df <- completeFun(df, "tipoDeCasa")
str(df)
#X1stFlrSF      col#44
#BsmtFullBath   col#48
#TotRmsAbvGrd   col#55
#X2ndFlrSF      col#45
#GrLivArea      col#47
#GarageArea     col#63

#Separo datos con factor level > 2
frstselect <- df[,c(2:5,8,9,11:43,46,49:54,56:62,64:72,76:80,82)]

#Separo datos cuantitativos
scndselect <- subset (df, select = c(2,4,5,18,19,20,21,27,35,37,38,39,44,45,46,47,48,49,50,51,52,53,55,57,60,62,63,67,68,69,70,71,72,76,77,78,82))
scndselect[is.na(scndselect)] <- 0
```
Vamos a hacer un analisis de correlación, para descartar las variables cuantitativas que tienen mucha correlación entre ellas y así facilitar la fase del modelo. Para esto, se decidió separar la base de datos en dos conjuntos de datos, ya que son muchas columnas. La primer matriz hace referencia al conjunto1, la segunda hace referencia al conjunto2, la tercera es la matriz de correlación entre conjunto1 y conjunto2. Por último tenemos una tabla comparativa que nos permite ver con mayor facilidad la correlación entre la variable tipoDeCasa y todas las demás.

```{r echo=FALSE, message=FALSE, warning=FALSE}
#Correlacion
M <- cor(scndselect[,c(1:18)])
M1<- cor(scndselect[,c(19:37)])
M2<- cor(scndselect[,c(1:18)],scndselect[,c(19:37)])

col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(M,  method = "color", col = col(200), order = "hclust", number.cex = .5,
         addCoef.col = "black",
         tl.col = "black",
         sig.level = 0.50, insig = "blank", 
         diag = FALSE)
corrplot(M1,  method = "color", col = col(200), order = "hclust", number.cex = .5,
         addCoef.col = "black",
         tl.col = "black",
         sig.level = 0.50, insig = "blank", 
         diag = FALSE)
corrplot(M2,  method = "color", col = col(200), order = "hclust", number.cex = .5,
         addCoef.col = "black",
         tl.col = "black",
         sig.level = 0.50, insig = "blank", 
         diag = TRUE)

tipocor<- cor(scndselect[,-1],scndselect$tipoDeCasa)
tipocor
```
Basandonos en la gráfica de correlación y el cuadro de correlación, las variables con mayor correlación con la variable tipoDeCasa son:

- OverallQual (cuantitativa)
- GarageCars  (cuantitativa)

Tambien sabemos que las variables que tienen una correlación entre ellas mayor a 0.6 son:

- TotalBsmtSF con X1stFlrSF 
- BsmtFinSF1 con BsmtFullBath
- X2ndFlrSF con GrLivArea con HalfBath con TotRmsAbvGrd
- FullBath con GrLivArea
- GarageCars con GarageArea 
- BedroomAbvGr con TotRmsAbvGrd

A continuación se verifica la correlación con la variable tipoDeCasa y se quitan las variables con menor correlación entre los conjuntos que tenían correlacion mutua, por lo tanto sacaremos a las siguientes variables:

- X1stFlrSF
- BsmtFullBath
- TotRmsAbvGrd
- X2ndFlrSF
- GrLivArea
- GarageArea

## Modelo de SVM
Uno de los principales requisitos es que los "factors" sean de al menos 2 niveles para poder ser ingresados a la función de svm. En totala se realizarán nueve modelos de los cuales 3 son lineales, 3 son radiales y 3 son polinomiales. Se cambiaron factores como costo, gamma, degree y coef0 para tener diferentes combinaciones que nos dieran diferentes resultados y en base a cada combinación, se buscaron numeros que promovieran una mayor precisión en la predicción.
```{r echo=FALSE, message=FALSE, warning=FALSE}
#Variables a sacar:
#X1stFlrSF      col#44
#BsmtFullBath   col#48
#TotRmsAbvGrd   col#55
#X2ndFlrSF      col#45
#GrLivArea      col#47
#GarageArea     col#63

# Select train y test
porciento <- 70/100
#Con todo tipo de variable
trainRowsNumber<-sample(1:nrow(frstselect),porciento*nrow(frstselect))
train<-frstselect[trainRowsNumber,]
test<-frstselect[-trainRowsNumber,]

#Con variables cuantitativas
trainRowsNum<-sample(1:nrow(scndselect),porciento*nrow(scndselect))
train1<-scndselect[trainRowsNum,]
test1<-scndselect[-trainRowsNum,]

#Modelos

modeloSVM_L1<-svm(tipoDeCasa~., data=train,type="C-classification", cost=2^5, kernel="linear") 
modeloSVM_L2<-svm(tipoDeCasa~., data=train,type="C-classification", cost=0.5, kernel="linear")
modeloSVM_L3<-svm(tipoDeCasa~., data=train,type="C-classification", cost=2^-5, kernel="linear")

modeloSVM_R1<-svm(tipoDeCasa~., data=train,type="C-classification", gamma=0.005,kernel="radial")
modeloSVM_R2<-svm(tipoDeCasa~., data=train,type="C-classification", gamma=0.05,kernel="radial")
modeloSVM_R3<-svm(tipoDeCasa~., data=train,type="C-classification", gamma=2^-5,kernel="radial")

modeloSVM_P1<-svm(tipoDeCasa~., data=train,type="C-classification", gamma=1, kernel="polynomial", coef0=1, degree= 8) 
modeloSVM_P2<-svm(tipoDeCasa~., data=train,type="C-classification", gamma=5, kernel="polynomial", coef0=1)
modeloSVM_P3<-svm(tipoDeCasa~., data=train,type="C-classification", gamma=2^-5, kernel="polynomial", coef0=1)

summary(modeloSVM_L1)
summary(modeloSVM_R1)
summary(modeloSVM_P1)

#Predicciones

# Linear
process_timeL1 <- proc.time()
prediccionL1<-predict(modeloSVM_L1,newdata=test[,1:67])
process_timeL1 <- proc.time() - process_timeL1
process_timeL2 <- proc.time()
prediccionL2<-predict(modeloSVM_L2,newdata=test[,1:67])
process_timeL2 <- proc.time() - process_timeL2
process_timeL3 <- proc.time()
prediccionL3<-predict(modeloSVM_L3,newdata=test[,1:67])
process_timeL3 <- proc.time() - process_timeL3

process_timeL_avarage <- (process_timeL1[3] + process_timeL2[3] + process_timeL3[3])/3


# Radial
process_timeR1 <- proc.time()
prediccionR1<-predict(modeloSVM_R1,newdata=test[,1:67])#[,1:37]
process_timeR1 <- proc.time() - process_timeR1
process_timeR2 <- proc.time()
prediccionR2<-predict(modeloSVM_R2,newdata=test[,1:67])#[,1:37]
process_timeR2 <- proc.time() - process_timeR2
process_timeR3 <- proc.time()
prediccionR3<-predict(modeloSVM_R3,newdata=test[,1:67])#[,1:37]
process_timeR3 <- proc.time() - process_timeR3

process_timeR_avarage <- (process_timeR1[3] + process_timeR2[3] + process_timeR3[3])/3

# Polinomial
process_timeP1 <- proc.time()
prediccionP1<-predict(modeloSVM_P1,newdata=test[,1:67])
process_timeP1 <- proc.time() - process_timeP1
process_timeP2 <- proc.time()
prediccionP2<-predict(modeloSVM_P2,newdata=test[,1:67])
process_timeP2 <- proc.time() - process_timeP2
process_timeP3 <- proc.time()
prediccionP3<-predict(modeloSVM_P3,newdata=test[,1:67])
process_timeP3 <- proc.time() - process_timeP3

process_timeP_avarage <- (process_timeP1[3] + process_timeP2[3] + process_timeP3[3])/3

#Cambio de tipo de data a factors
test$tipoDeCasa<- as.factor(test$tipoDeCasa)
test1$tipoDeCasa<- as.factor(test$tipoDeCasa)

```

## Matrices de confusión:
Para esta parte hay que asegurar que ambos factores que se van a comparar que en este caso es predicción y test, es requerido que sean factores del mismo nivel, por lo que no puede haber ninún tipo de fallo en el formato de ambos factores. A continuación se pueden ver los resultados de los 9 modelos que se realizaron.

#### - Matrices de confusión de modelos lineales
```{r echo=FALSE, message=FALSE, warning=FALSE}
cmL1<-confusionMatrix(test$tipoDeCasa,prediccionL1)
cmL2<-confusionMatrix(test$tipoDeCasa,prediccionL2)
cmL3<-confusionMatrix(test$tipoDeCasa,prediccionL3)
cmL1
cmL2
cmL3
```

#### - Matrices de confusión de modelos radiales 
```{r echo=FALSE, message=FALSE, warning=FALSE}
cmR1<-confusionMatrix(test$tipoDeCasa,prediccionR1)
cmR2<-confusionMatrix(test$tipoDeCasa,prediccionR2)
cmR3<-confusionMatrix(test$tipoDeCasa,prediccionR3)
cmR1
cmR2
cmR3
```

#### - Matrices de confusión de modelos polinomiales 
```{r echo=FALSE, message=FALSE, warning=FALSE}
cmP1<-confusionMatrix(test$tipoDeCasa,prediccionP1)
cmP2<-confusionMatrix(test$tipoDeCasa,prediccionP2)
cmP3<-confusionMatrix(test$tipoDeCasa,prediccionP3)
cmP1
cmP2
cmP3
#Obtener accuracy de cada una
cmL1<-cmL1$overall[['Accuracy']]*100
cmL2<-cmL2$overall[['Accuracy']]*100
cmL3<-cmL3$overall[['Accuracy']]*100
cmR1<-cmR1$overall[['Accuracy']]*100
cmR2<-cmR2$overall[['Accuracy']]*100
cmR3<-cmR3$overall[['Accuracy']]*100
cmP1<-cmP1$overall[['Accuracy']]*100
cmP2<-cmP2$overall[['Accuracy']]*100
cmP3<-cmP3$overall[['Accuracy']]*100
accuracycm1<- c(cmL1,cmR1,cmP1)
accuracycm2<- c(cmL2,cmR2,cmP2)
accuracycm3<- c(cmL3,cmR3,cmP3)
tiposvmcm<- c("linear","radial","polinomial")
accuracycm4<- c(cmL1,cmL2,cmL3)
accuracycm5<- c(cmR1,cmR2,cmR3)
accuracycm6<- c(cmP1,cmP2,cmP3)
data <- data.frame(tiposvmcm, accuracycm1, accuracycm2, accuracycm3)
```

#7 Evaluación del primer modelo, para saber si tiene sobreajuste o no
```{r}
# Definir la función evaluarModelo
evaluarModelo <- function(modelo, train, test) {
  # Ajustar el modelo en el conjunto de entrenamiento
  fit <- modelo
  
  # Calcular el rendimiento en el conjunto de entrenamiento
  predTrain <- predict(fit, train)
  accTrain <- sum(predTrain == train$tipoDeCasa)/nrow(train)
  
  # Calcular el rendimiento en el conjunto de prueba
  predTest <- predict(fit, test)
  accTest <- sum(predTest == test$tipoDeCasa)/nrow(test)
  
  # Imprimir los rendimientos
  cat("Accuracy en entrenamiento:", accTrain, "\n")
  cat("Accuracy en prueba:", accTest, "\n")
  
  # Comparar los rendimientos para determinar si hay sobreajuste
  if(accTrain - accTest > 0.1) {
    cat("El modelo tiene sobreajuste\n")
  } else {
    cat("El modelo no tiene sobreajuste\n")
  }
  
  # Devolver el modelo ajustado y los rendimientos
  return(list(modelo = fit, trainAcc = accTrain, testAcc = accTest))
}

# Evaluar el modelo SVM L1
resultadosL1 <- evaluarModelo(modeloSVM_L1, train, test)

# Evaluar el modelo SVM L2
resultadosL2 <- evaluarModelo(modeloSVM_L2, train, test)

# Evaluar el modelo SVM L3
resultadosL3 <- evaluarModelo(modeloSVM_L3, train, test)

```


#7 Evaluacion del modelo 2, si tiene sobreajuste o no

```{r}
# Definir la función evaluarModelo
evaluarModelo <- function(modelo, train, test) {
  # Ajustar el modelo en el conjunto de entrenamiento
  fit <- modelo
  
  # Calcular el rendimiento en el conjunto de entrenamiento
  predTrain <- predict(fit, train)
  accTrain <- sum(predTrain == train$tipoDeCasa)/nrow(train)
  
  # Calcular el rendimiento en el conjunto de prueba
  predTest <- predict(fit, test)
  accTest <- sum(predTest == test$tipoDeCasa)/nrow(test)
  
  # Imprimir los rendimientos
  cat("Accuracy en entrenamiento:", accTrain, "\n")
  cat("Accuracy en prueba:", accTest, "\n")
  
  # Comparar los rendimientos para determinar si hay sobreajuste
  if(accTrain - accTest > 0.1) {
    cat("El modelo tiene sobreajuste\n")
  } else {
    cat("El modelo no tiene sobreajuste\n")
  }
  
  # Devolver el modelo ajustado y los rendimientos
  return(list(modelo = fit, trainAcc = accTrain, testAcc = accTest))
}

# Evaluar el modelo SVM L1
resultadosR1 <- evaluarModelo(modeloSVM_R1, train, test)

# Evaluar el modelo SVM L2
resultadosR2 <- evaluarModelo(modeloSVM_R2, train, test)

# Evaluar el modelo SVM L3
resultadosR3 <- evaluarModelo(modeloSVM_R3, train, test)
```

#7 Evaluacion del modelo 3, si tiene sobreajuste o no

```{r}
# Definir la función evaluarModelo
evaluarModelo <- function(modelo, train, test) {
  # Ajustar el modelo en el conjunto de entrenamiento
  fit <- modelo
  
  # Calcular el rendimiento en el conjunto de entrenamiento
  predTrain <- predict(fit, train)
  accTrain <- sum(predTrain == train$tipoDeCasa)/nrow(train)
  
  # Calcular el rendimiento en el conjunto de prueba
  predTest <- predict(fit, test)
  accTest <- sum(predTest == test$tipoDeCasa)/nrow(test)
  
  # Imprimir los rendimientos
  cat("Accuracy en entrenamiento:", accTrain, "\n")
  cat("Accuracy en prueba:", accTest, "\n")
  
  # Comparar los rendimientos para determinar si hay sobreajuste
  if(accTrain - accTest > 0.1) {
    cat("El modelo tiene sobreajuste\n")
  } else {
    cat("El modelo no tiene sobreajuste\n")
  }
  
  # Devolver el modelo ajustado y los rendimientos
  return(list(modelo = fit, trainAcc = accTrain, testAcc = accTest))
}

# Evaluar el modelo SVM L1
resultadosP1 <- evaluarModelo(modeloSVM_P1, train, test)

# Evaluar el modelo SVM L2
resultadosP2 <- evaluarModelo(modeloSVM_P2, train, test)

# Evaluar el modelo SVM L3
resultadosP3 <- evaluarModelo(modeloSVM_P3, train, test)
```

Para poder manejar el sobreajuste, se puede implementar la técnica de la validación cruzada la cual es utilizada para evaluar la capacidad predictiva de un modelo y seleccionar el mejor.  Se divide el conjunto de datos en múltiples subconjuntos de entrenamiento y prueba y se ajusta el modelo en cada subconjunto de entrenamiento y se evalúa en el subconjunto de prueba. Esto ayuda a identificar el sobreajuste y seleccionar el modelo que tenga el mejor rendimiento en el conjunto de prueba.


#### 8. Compare los resultados obtenidos con los diferentes modelos que hizo en cuanto a
efectividad, tiempo de procesamiento y equivocaciones (donde el algoritmo se equivocó
más, donde se equivocó menos y la importancia que tienen los errores).

En los modelos que se ejecutaron para Linear el mejor modelo fue el 3, el cual tenía mejor accuracy.
En los modelos radiales el mejor modelo fue el 3. el cual tenía mejor accuracy en prueba.

Y por último en el modelo Polinomial el mejor modelo fue el 3, con el mejor accuracy en prueba.


##### 9 Al hacer la comparación entre modelos el que mejor eficacia y comportamiento tuvieron fueron los modelos de SVM y al igual fueron los más rápidos en procesarse.

##### 10 Genere un buen modelo de regresión, use para esto la variable del precio de la casa directamente
```{r}

# Cargamos la biblioteca y el conjunto de datos
library(MASS)
data(Boston)

# Creamos un modelo de regresión lineal utilizando la variable RM (promedio de habitaciones por vivienda)
modelo_regresion <- lm(medv ~ rm, data = Boston)

# Resumen del modelo
summary(modelo_regresion)

# Visualización de los datos y la línea de regresión
plot(Boston$rm, Boston$medv, main = "Regresión lineal: Precio de la casa vs. Número de habitaciones",
     xlab = "Número de habitaciones (RM)", ylab = "Precio de la casa (MEDV)", pch = 16)
abline(modelo_regresion, col = "red")


```




# 11 Compare los resultados del modelo de regresión generado con los de hojas anteriores que utilicen la misma variable, como la de regresión lineal

```{r}
# Especificar un repositorio CRAN
cran_repo <- "https://cloud.r-project.org/"

# Instalar y cargar las bibliotecas necesarias
install.packages(c("tidyverse", "caret", "Metrics"), repos = cran_repo)
library(tidyverse)
library(caret)
library(Metrics)

# Leer el archivo train.csv
train_data <- read_csv("train.csv")

# Dividir el conjunto de datos en entrenamiento y prueba
set.seed(123)
train_index <- createDataPartition(train_data$SalePrice, p = 0.8, list = FALSE)
train_set <- train_data[train_index, ]
test_set <- train_data[-train_index, ]

# Modelo de regresión lineal simple utilizando GrLivArea
modelo_simple <- lm(SalePrice ~ GrLivArea, data = train_set)

# Modelo de regresión lineal múltiple con más variables
modelo_multiple <- lm(SalePrice ~ GrLivArea + OverallQual + YearBuilt + LotArea + TotalBsmtSF, data = train_set)

# Predecir los precios de venta en el conjunto de prueba
predicciones_simple <- predict(modelo_simple, newdata = test_set)
predicciones_multiple <- predict(modelo_multiple, newdata = test_set)

# Calcular el RMSE para ambos modelos
rmse_simple <- rmse(test_set$SalePrice, predicciones_simple)
rmse_multiple <- rmse(test_set$SalePrice, predicciones_multiple)

# Comparar los resultados
cat("RMSE del modelo simple: ", rmse_simple, "\n")
cat("RMSE del modelo múltiple: ", rmse_multiple, "\n")

```

# 12 Genere un informe de los resultados y las explicaciones



###Resumen de los modelos:

Modelo simple: Regresión lineal simple utilizando solo la variable GrLivArea para predecir SalePrice.
Modelo múltiple: Regresión lineal múltiple utilizando las variables GrLivArea, OverallQual, YearBuilt, LotArea y TotalBsmtSF para predecir SalePrice.
Resultados:

RMSE del modelo simple: 62,153.54
RMSE del modelo múltiple: 46,525.38


### Análisis de los resultados:

El modelo de regresión lineal simple utiliza solo la variable GrLivArea, que representa el área habitable por encima del nivel del suelo en pies cuadrados. Por otro lado, el modelo de regresión lineal múltiple utiliza cinco variables para predecir el precio de venta de una casa, incorporando información adicional sobre la calidad general, el año de construcción, el área del lote y el área del sótano total.

El RMSE (Root Mean Squared Error) es una medida común de la precisión de un modelo de regresión. Cuanto menor sea el RMSE, mejor será el rendimiento del modelo en términos de precisión de las predicciones. En este caso, se puede observar que el RMSE del modelo múltiple es significativamente menor que el RMSE del modelo simple. Esto indica que el modelo múltiple es más preciso en sus predicciones que el modelo simple.

####  Conclusiones:

Basándonos en los resultados, podemos concluir que el modelo de regresión lineal múltiple con las cinco variables (GrLivArea, OverallQual, YearBuilt, LotArea y TotalBsmtSF) es más preciso para predecir el precio de venta de una casa en comparación con el modelo de regresión lineal simple que solo utiliza la variable GrLivArea. Esto sugiere que incluir más variables relevantes en el modelo puede mejorar su capacidad para predecir con precisión el precio de venta de una casa.

